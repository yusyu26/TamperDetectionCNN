#!/usr/bin/env python3
"""
ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
æ”¹ã–ã‚“ç”»åƒã®æšæ•°ã«åˆã‚ã›ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’é¸æŠã—ã€å„ã‚¯ãƒ©ã‚¹åŒã˜æšæ•°ã§ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹
"""

import os
import glob
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
import cv2
import random
import yaml
from typing import List, Tuple, Dict, Any
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

from utils_90percent import create_7_channel_features, normalize_image


class BalancedSaigen90Dataset(Dataset):
    """ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿Saigen90Dataset"""
    
    def __init__(self, image_paths: List[str], labels: List[int], config: Dict[str, Any], mode: str = 'train'):
        """
        Args:
            image_paths: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
            labels: ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆ0: ã‚ªãƒªã‚¸ãƒŠãƒ«, 1: æ”¹ã–ã‚“ï¼‰
            config: è¨­å®šè¾æ›¸
            mode: 'train', 'val', 'test'ã®ã„ãšã‚Œã‹
        """
        self.image_paths = image_paths
        self.labels = labels
        self.config = config
        self.mode = mode
        
        # è¨­å®šæŠ½å‡º
        self.image_size = tuple(config['dataset']['image_size'])
        self.preprocessing_config = config['preprocessing']
        
        print(f"ğŸ“Š BalancedDataset[{mode}]: {len(self.image_paths)} samples")
        print(f"   ã‚ªãƒªã‚¸ãƒŠãƒ«: {labels.count(0)} / æ”¹ã–ã‚“: {labels.count(1)}")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ãƒ‡ãƒ¼ã‚¿å–å¾—
        
        Returns:
            features: 23ãƒãƒ£ãƒ³ãƒãƒ«ç‰¹å¾´é‡ (23, H, W)
            label: ãƒ©ãƒ™ãƒ« (scalar)
        """
        # ç”»åƒèª­ã¿è¾¼ã¿
        image_path = self.image_paths[idx]
        image = cv2.imread(image_path)
        
        if image is None:
            raise RuntimeError(f"ç”»åƒèª­ã¿è¾¼ã¿å¤±æ•—: {image_path}")
        
        # BGR â†’ RGBå¤‰æ›
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ãƒªã‚µã‚¤ã‚º
        image = cv2.resize(image, self.image_size)
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆè¨“ç·´æ™‚ã®ã¿é©ç”¨ï¼‰
        if self.mode == 'train':
            image = self._apply_data_augmentation(image)
        # 7ãƒãƒ£ãƒ³ãƒãƒ«ç‰¹å¾´é‡æŠ½å‡º
        features = create_7_channel_features(image, self.config)
        
        # æ­£è¦åŒ–
        if self.preprocessing_config.get('normalize', True):
            features = normalize_image(features)
        
        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ› (H, W, C) â†’ (C, H, W)
        features = torch.from_numpy(features).float().permute(2, 0, 1)
        label = torch.tensor(self.labels[idx], dtype=torch.long)
        
        return features, label
    
    def _apply_data_augmentation(self, image: np.ndarray) -> np.ndarray:
        """
        ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®é©ç”¨ï¼ˆæ”¹ã–ã‚“ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®ã—ã¦æ§ãˆã‚ï¼‰
        
        Args:
            image: RGBç”»åƒ (H, W, 3)
        
        Returns:
            æ‹¡å¼µæ¸ˆã¿ç”»åƒ (H, W, 3)
        """
        # è¨­å®šã‹ã‚‰æ‹¡å¼µãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        augmentation_config = self.config.get('augmentation', {})
        
        # æ°´å¹³åè»¢
        horizontal_flip = augmentation_config.get('horizontal_flip', 0)
        if horizontal_flip > 0 and random.random() < horizontal_flip:
            image = cv2.flip(image, 1)
        
        # å›è»¢
        rotation_range = augmentation_config.get('rotation_range', 0)
        if rotation_range > 0:
            angle = random.uniform(-rotation_range, rotation_range)
            center = (image.shape[1] // 2, image.shape[0] // 2)
            matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            image = cv2.warpAffine(image, matrix, (image.shape[1], image.shape[0]), borderMode=cv2.BORDER_REFLECT)
        
        # æ˜åº¦èª¿æ•´
        brightness_range = augmentation_config.get('brightness_range', 0)
        if brightness_range > 0:
            brightness_factor = 1.0 + random.uniform(-brightness_range, brightness_range)
            image = np.clip(image * brightness_factor, 0, 255).astype(np.uint8)
        
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
        contrast_range = augmentation_config.get('contrast_range', 0)
        if contrast_range > 0:
            contrast_factor = 1.0 + random.uniform(-contrast_range, contrast_range)
            image = np.clip((image - 128) * contrast_factor + 128, 0, 255).astype(np.uint8)
        
        return image


def load_balanced_dataset_paths(config: Dict[str, Any]) -> Tuple[List[str], List[int]]:
    """
    ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã¨ãƒ©ãƒ™ãƒ«ã‚’èª­ã¿è¾¼ã¿
    æ”¹ã–ã‚“ç”»åƒã®æšæ•°ã«åˆã‚ã›ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    
    Args:
        config: è¨­å®šè¾æ›¸
    
    Returns:
        image_paths: ç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ï¼‰
        labels: ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆ0: ã‚ªãƒªã‚¸ãƒŠãƒ«, 1: æ”¹ã–ã‚“ï¼‰
    """
    dataset_config = config['dataset']
    data_path = dataset_config['data_path']
    authentic_folder = dataset_config['authentic_folder']
    tampered_folder = dataset_config['tampered_folder']
    seed = dataset_config.get('seed', 42)
    
    # ã‚·ãƒ¼ãƒ‰è¨­å®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
    random.seed(seed)
    np.random.seed(seed)
    
    image_paths = []
    labels = []
    
    # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒèª­ã¿è¾¼ã¿
    authentic_path = os.path.join(data_path, authentic_folder)
    authentic_files = (glob.glob(os.path.join(authentic_path, "*.jpg")) + 
                  glob.glob(os.path.join(authentic_path, "*.tif")))
    
    # æ”¹ã–ã‚“ç”»åƒèª­ã¿è¾¼ã¿ï¼ˆå…¨ã¦ä½¿ç”¨ï¼‰
    tampered_path = os.path.join(data_path, tampered_folder)
    tampered_files = (glob.glob(os.path.join(tampered_path, "*.jpg")) + 
                  glob.glob(os.path.join(tampered_path, "*.tif")))

    print(f"ğŸ“ å…ƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±:")
    print(f"   ã‚ªãƒªã‚¸ãƒŠãƒ«: {len(authentic_files)} æš")
    print(f"   æ”¹ã–ã‚“: {len(tampered_files)} æš")
    
    # æ”¹ã–ã‚“ç”»åƒã®æšæ•°ã«åˆã‚ã›ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    target_count = len(tampered_files)
    
    if len(authentic_files) >= target_count:
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒãŒååˆ†ã‚ã‚‹å ´åˆï¼šãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        sampled_authentic_files = random.sample(authentic_files, target_count)
        print(f"ğŸ¯ ãƒãƒ©ãƒ³ã‚¹èª¿æ•´: ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’ {len(authentic_files)} â†’ {target_count} æšã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
    else:
        # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆï¼šã‚¨ãƒ©ãƒ¼
        raise ValueError(
            f"ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚\n"
            f"å¿…è¦æšæ•°: {target_count} æš\n"
            f"åˆ©ç”¨å¯èƒ½æšæ•°: {len(authentic_files)} æš\n"
            f"æ”¹ã–ã‚“ç”»åƒã®æšæ•°ã‚’æ¸›ã‚‰ã™ã‹ã€ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
        )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ§‹ç¯‰
    # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒï¼ˆãƒ©ãƒ™ãƒ«0ï¼‰
    image_paths.extend(sampled_authentic_files)
    labels.extend([0] * len(sampled_authentic_files))
    
    # æ”¹ã–ã‚“ç”»åƒï¼ˆãƒ©ãƒ™ãƒ«1ï¼‰- å…¨ã¦ä½¿ç”¨
    image_paths.extend(tampered_files)
    labels.extend([1] * len(tampered_files))
    
    print(f"ğŸ“Š ãƒãƒ©ãƒ³ã‚¹èª¿æ•´å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
    print(f"   ã‚ªãƒªã‚¸ãƒŠãƒ«: {labels.count(0)} æš")
    print(f"   æ”¹ã–ã‚“: {labels.count(1)} æš")
    print(f"   åˆè¨ˆ: {len(image_paths)} æš")
    print(f"   ãƒãƒ©ãƒ³ã‚¹æ¯”: {labels.count(0)}:{labels.count(1)} (1:1)")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ï¼ˆãƒãƒ©ãƒ³ã‚¹ã‚’ä¿ã£ãŸã¾ã¾ï¼‰
    combined = list(zip(image_paths, labels))
    random.shuffle(combined)
    image_paths, labels = zip(*combined)
    
    return list(image_paths), list(labels)


def create_balanced_data_splits(image_paths: List[str], labels: List[int], config: Dict[str, Any]) -> Tuple[
    Tuple[List[str], List[int]], 
    Tuple[List[str], List[int]], 
    Tuple[List[str], List[int]]
]:
    """
    ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¨“ç·´ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆã«åˆ†å‰²
    åˆ†å‰²æ™‚ã‚‚ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿æŒ
    
    Args:
        image_paths: ç”»åƒãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        labels: ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆ
        config: è¨­å®šè¾æ›¸
    
    Returns:
        (train_paths, train_labels): è¨“ç·´ãƒ‡ãƒ¼ã‚¿
        (val_paths, val_labels): æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
        (test_paths, test_labels): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    """
    dataset_config = config['dataset']
    train_ratio = dataset_config['train_ratio']
    val_ratio = dataset_config['val_ratio']
    test_ratio = dataset_config['test_ratio']
    seed = dataset_config['seed']
    
    # æ¯”ç‡ã®ç¢ºèª
    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "åˆ†å‰²æ¯”ç‡ã®åˆè¨ˆãŒ1ã«ãªã‚Šã¾ã›ã‚“"
    
    print(f"ğŸ”€ ãƒãƒ©ãƒ³ã‚¹ä¿æŒãƒ‡ãƒ¼ã‚¿åˆ†å‰²é–‹å§‹:")
    print(f"   åˆ†å‰²å‰ - ã‚ªãƒªã‚¸ãƒŠãƒ«: {labels.count(0)}, æ”¹ã–ã‚“: {labels.count(1)}")
    
    # stratifyã‚’ä½¿ç”¨ã—ã¦ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’ä¿æŒã—ãªãŒã‚‰åˆ†å‰²
    # ã¾ãšè¨“ç·´+æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(
        image_paths, labels, test_size=test_ratio, 
        random_state=seed, stratify=labels
    )
    
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    adjusted_val_ratio = val_ratio / (train_ratio + val_ratio)
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        train_val_paths, train_val_labels, test_size=adjusted_val_ratio,
        random_state=seed, stratify=train_val_labels
    )
    
    # åˆ†å‰²çµæœã®ç¢ºèª
    print(f"ğŸ”€ ãƒãƒ©ãƒ³ã‚¹ä¿æŒãƒ‡ãƒ¼ã‚¿åˆ†å‰²å®Œäº†:")
    print(f"   è¨“ç·´: {len(train_paths)} æš (ã‚ªãƒªã‚¸ãƒŠãƒ«: {train_labels.count(0)}, æ”¹ã–ã‚“: {train_labels.count(1)})")
    print(f"   æ¤œè¨¼: {len(val_paths)} æš (ã‚ªãƒªã‚¸ãƒŠãƒ«: {val_labels.count(0)}, æ”¹ã–ã‚“: {val_labels.count(1)})")
    print(f"   ãƒ†ã‚¹ãƒˆ: {len(test_paths)} æš (ã‚ªãƒªã‚¸ãƒŠãƒ«: {test_labels.count(0)}, æ”¹ã–ã‚“: {test_labels.count(1)})")
    
    # ãƒãƒ©ãƒ³ã‚¹ç¢ºèª
    def check_balance(label_list, name):
        original_count = label_list.count(0)
        tampered_count = label_list.count(1)
        balance_ratio = original_count / tampered_count if tampered_count > 0 else 0
        print(f"   {name}ãƒãƒ©ãƒ³ã‚¹æ¯”: {original_count}:{tampered_count} (æ¯”ç‡: {balance_ratio:.2f})")
    
    check_balance(train_labels, "è¨“ç·´")
    check_balance(val_labels, "æ¤œè¨¼")
    check_balance(test_labels, "ãƒ†ã‚¹ãƒˆ")
    
    return (train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels)


def create_balanced_data_loaders(config: Dict[str, Any]) -> Tuple[DataLoader, DataLoader, DataLoader]:
    """
    ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆ
    
    Args:
        config: è¨­å®šè¾æ›¸
    
    Returns:
        train_loader: è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        val_loader: æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        test_loader: ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    """
    # ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    image_paths, labels = load_balanced_dataset_paths(config)
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ï¼ˆãƒãƒ©ãƒ³ã‚¹ä¿æŒï¼‰
    (train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels) = create_balanced_data_splits(
        image_paths, labels, config
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    train_dataset = BalancedSaigen90Dataset(train_paths, train_labels, config, mode='train')
    val_dataset = BalancedSaigen90Dataset(val_paths, val_labels, config, mode='val')
    test_dataset = BalancedSaigen90Dataset(test_paths, test_labels, config, mode='test')
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆï¼ˆDockerç’°å¢ƒå¯¾å¿œï¼‰
    training_config = config['training']
    batch_size = training_config['batch_size']
    num_workers = 0  # Dockerç’°å¢ƒã§ã¯0ã«å›ºå®š
    pin_memory = False  # Dockerç’°å¢ƒã§ã¯ç„¡åŠ¹åŒ–
    
    # å†ç¾æ€§ã®ãŸã‚ã®generatorè¨­å®š
    seed = config['dataset']['seed']
    g = torch.Generator()
    g.manual_seed(seed)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True,
        generator=g  # å†ç¾æ€§ã®ãŸã‚
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    
    test_loader = DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    
    print(f"ğŸš€ ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆå®Œäº†:")
    print(f"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}")
    print(f"   ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {num_workers}")
    print(f"   è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}")
    print(f"   æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}")
    print(f"   ãƒ†ã‚¹ãƒˆãƒãƒƒãƒæ•°: {len(test_loader)}")
    
    return train_loader, val_loader, test_loader


def analyze_dataset_balance(config: Dict[str, Any]):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒãƒ©ãƒ³ã‚¹ã‚’åˆ†æï¼ˆå®Ÿè¡Œå‰ã®ç¢ºèªç”¨ï¼‰
    """
    dataset_config = config['dataset']
    data_path = dataset_config['data_path']
    authentic_folder = dataset_config['authentic_folder']
    tampered_folder = dataset_config['tampered_folder']
    
    # ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒ
    authentic_path = os.path.join(data_path, authentic_folder)
    authentic_files = glob.glob(os.path.join(authentic_path, "*.jpg"))
    
    # æ”¹ã–ã‚“ç”»åƒ
    tampered_path = os.path.join(data_path, tampered_folder)
    tampered_files = glob.glob(os.path.join(tampered_path, "*.jpg"))
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒãƒ©ãƒ³ã‚¹åˆ†æ:")
    print(f"   ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒ: {len(authentic_files)} æš")
    print(f"   æ”¹ã–ã‚“ç”»åƒ: {len(tampered_files)} æš")
    print(f"   å…ƒã®æ¯”ç‡: {len(authentic_files)}:{len(tampered_files)}")
    
    target_count = len(tampered_files)
    print(f"   ãƒãƒ©ãƒ³ã‚¹èª¿æ•´å¾Œ: å„ã‚¯ãƒ©ã‚¹ {target_count} æš")
    print(f"   ç·ä½¿ç”¨æšæ•°: {target_count * 2} æš")
    
    if len(authentic_files) > len(tampered_files):
        unused_count = len(authentic_files) - len(tampered_files)
        print(f"   âš ï¸ ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‹ã‚‰ {unused_count} æšãŒä½¿ç”¨ã•ã‚Œã¾ã›ã‚“")
    elif len(authentic_files) < len(tampered_files):
        print(f"   âŒ ã‚¨ãƒ©ãƒ¼: ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        return False
    else:
        print(f"   âœ… å®Œå…¨ãƒãƒ©ãƒ³ã‚¹: èª¿æ•´ä¸è¦")
    
    return True


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("=" * 60)
    print("ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿Saigen90 ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # è¨­å®šèª­ã¿è¾¼ã¿
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    try:
        # ãƒãƒ©ãƒ³ã‚¹åˆ†æ
        if not analyze_dataset_balance(config):
            print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒãƒ©ãƒ³ã‚¹åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            exit(1)
        
        print("\n" + "="*60)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
        train_loader, val_loader, test_loader = create_balanced_data_loaders(config)
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        print("\nğŸ” ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç¢ºèª:")
        for batch_idx, (features, labels) in enumerate(train_loader):
            print(f"   ãƒãƒƒãƒ {batch_idx + 1}:")
            print(f"     ç‰¹å¾´é‡å½¢çŠ¶: {features.shape}")  # (B, 23, H, W)
            print(f"     ãƒ©ãƒ™ãƒ«å½¢çŠ¶: {labels.shape}")    # (B,)
            print(f"     ç‰¹å¾´é‡ç¯„å›²: [{features.min():.3f}, {features.max():.3f}]")
            print(f"     ãƒ©ãƒ™ãƒ«: {labels.tolist()}")
            print(f"     ãƒãƒƒãƒå†…ãƒãƒ©ãƒ³ã‚¹: ã‚ªãƒªã‚¸ãƒŠãƒ« {(labels == 0).sum().item()} / æ”¹ã–ã‚“ {(labels == 1).sum().item()}")
            
            if batch_idx >= 2:  # æœ€åˆã®3ãƒãƒƒãƒã®ã¿ç¢ºèª
                break
        
        print(f"\nâœ… ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        print(f"ğŸ¯ æ”¹ã–ã‚“ç”»åƒã®æšæ•°ã«åˆã‚ã›ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç”»åƒã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()