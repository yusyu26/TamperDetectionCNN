import torch
import yaml
import argparse
from tqdm import tqdm
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

from model import SaigenCNN
from balanced_data_loader import create_balanced_data_loaders

def evaluate(config):
    """
    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ã€æ··åŒè¡Œåˆ—ã‚’ä½œæˆã™ã‚‹é–¢æ•°
    """
    device = torch.device("cpu")
    print(f"Using device: {device}")

    _, _, test_loader = create_balanced_data_loaders(config)

    model = SaigenCNN(
        in_channels=config['model']['in_channels'],
        num_classes=config['model']['num_classes']
    ).to(device)

    # 3. ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™
    model_path = config['training']['model_save_path']
    try:
        # PyTorchã®è­¦å‘Šã‚’é¿ã‘ã‚‹ãŸã‚ã€weights_only=Trueã‚’è¿½åŠ 
        model.load_state_dict(torch.load(model_path, map_location=device))
        print(f"\nLoaded best model from: {model_path}")
    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{model_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
    except RuntimeError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ã¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ãŒã€å­¦ç¿’æ™‚ã¨å®Œå…¨ã«ä¸€è‡´ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print(e)
        return

    # 4. è©•ä¾¡ã‚’å®Ÿè¡Œ
    model.eval()
    all_preds = []
    all_labels = []

    print("Evaluating on test set...")
    with torch.no_grad():
        for inputs, labels in tqdm(test_loader, desc="Testing"):
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # 5. çµæœã‚’è¡¨ç¤ºã—ã€ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜
    accuracy = (np.array(all_preds) == np.array(all_labels)).mean()
    print(f"\nâœ… Final Test Accuracy: {accuracy * 100:.2f}%")

    class_names = ['Original', 'Tampered']
    print("\nClassification Report:")
    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))

    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('Confusion Matrix on Test Set')
    plt.ylabel('Actual Label')
    plt.xlabel('Predicted Label')

    plot_path = 'confusion_matrix.png'
    plt.savefig(plot_path)
    print(f"ğŸ“ˆ Confusion matrix plot saved to {plot_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Evaluate a trained model.")
    parser.add_argument('--config', type=str, required=True, help="Path to the config YAML file.")
    args = parser.parse_args()

    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)

    evaluate(config)